{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f140bd",
   "metadata": {},
   "source": [
    "# Sequence Model Training\n",
    "## Metadata Single-Record Embeddings to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0596dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 01:19:47.927567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from modules import utils, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faaeedb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'modules.utils' has no attribute '_index_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25410/170888286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            \u001b[0mscaler_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../models/scalers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                            include_index=True)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mindex_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/master_train_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmetadata_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/metadata_single_rec.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'modules.utils' has no attribute '_index_map'"
     ]
    }
   ],
   "source": [
    "metadata_train_gen = utils.CombinedDataGen(data_file='../data/master_train_df.csv',\n",
    "                                           out_mode='meta',\n",
    "                                           mode='test',\n",
    "                                           shuffle=False,\n",
    "                                           scaler_dir='../models/scalers',\n",
    "                                           include_index=True)\n",
    "index_map = utils._index_map('../data/master_train_df.csv')\n",
    "metadata_mdl = tf.keras.models.load_model('../models/metadata_single_rec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43916d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_embeddings(generator=metadata_gen, \n",
    "                       out_mode='meta',\n",
    "                       mode='train',\n",
    "                       model=metadata_mdl,\n",
    "                       index_map=index_map,\n",
    "                       save_dir='../data/metadata_sequence_train.pkl',\n",
    "                       nb_eps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb0b1e",
   "metadata": {},
   "source": [
    "## Train Metadata Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27d77265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_gen_items(tensor_item, mode, out_mode):\n",
    "\n",
    "    if mode == 'train':\n",
    "        if out_mode == 'meta':\n",
    "            ds = tf.data.Dataset.from_tensors(({'meta_0':tensor_item[0]['meta_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32'))).batch(1)\n",
    "        if out_mode == 'image':\n",
    "            ds = tf.data.Dataset.from_tensors(({'img_0':tensor_item[0]['img_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32')))\n",
    "            ds = ds.map(utils._process_aug).batch(1)\n",
    "        if out_mode == 'combined':\n",
    "            ds = tf.data.Dataset.from_tensors(({'meta_0':tensor_item[0]['meta_0'].astype('float32'),\n",
    "                                                'img_0':tensor_item[0]['img_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32')))\n",
    "            ds = ds.map(utils._process_aug).batch(1)\n",
    "    else:\n",
    "        if out_mode=='meta':\n",
    "            ds = tf.data.Dataset.from_tensors(({'meta_0':tensor_item[0]['meta_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32'))).batch(1)\n",
    "        if out_mode == 'image':\n",
    "            ds = tf.data.Dataset.from_tensors(({'img_0':tensor_item[0]['img_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32')))\n",
    "            ds = ds.map(utils._process).batch(1)\n",
    "        if out_mode == 'combined':\n",
    "            ds = tf.data.Dataset.from_tensors(({'meta_0':tensor_item[0]['meta_0'].astype('float32'),\n",
    "                                                'img_0':tensor_item[0]['img_0'].astype('float32')},\n",
    "                                               tensor_item[1].astype('float32')))\n",
    "            ds = ds.map(utils._process).batch(1)\n",
    "    return ds\n",
    "\n",
    "def _index_map(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    idx_map = {}\n",
    "    for row_idx in df.index:\n",
    "        part_id = df.loc[row_idx, 'participant_id']\n",
    "        scan_date = df.loc[row_idx, 'scan_date']\n",
    "        idx_map[row_idx] = [part_id, scan_date]\n",
    "        \n",
    "    return idx_map\n",
    "\n",
    "def write_embeddings(generator, mode, out_mode, model, index_map, \n",
    "                     save_dir, nb_eps=1):\n",
    "    emb_ds = {}\n",
    "    \n",
    "    for ep in range(nb_eps):\n",
    "        print(ep)\n",
    "        data = {}\n",
    "        \n",
    "        for item, r_idx in tqdm(generator):\n",
    "            r_idx = r_idx[0]\n",
    "            inp, lbl = item\n",
    "            ds = _process_gen_items([inp, lbl], mode, out_mode)\n",
    "            emb = np.squeeze(model.predict(ds)[0])\n",
    "            sdate, part_id = index_map[r_idx]\n",
    "            sample = {sdate: [emb, lbl]}\n",
    "            try:\n",
    "                data[part_id][sdate] = [emb, lbl]\n",
    "            except KeyError:\n",
    "                data[part_id] = sample\n",
    "        emb_ds[ep] = data\n",
    "        \n",
    "    with open(save_dir, 'wb') as handle:\n",
    "        pickle.dump(emb_ds, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_seq_mdl = models.init_seq_model(inp_shape=33)\n",
    "metadata_seq_gen = utils.sequence_generator(data_file='../data/metadata_sequence_train.pkl',\n",
    "                                            batch_size=64,\n",
    "                                            emb_shape=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a997e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cb = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                min_delta=1e-8,\n",
    "                                patience=30,\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "metadata_seq_mdl.fit(metadata_seq_gen, \n",
    "                     epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4717396",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_seq_mdl.save('../models/metadata_sequence_rec.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioEnv",
   "language": "python",
   "name": "bioenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
